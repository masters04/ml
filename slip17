20.	Implement Ensemble ML algorithm on Pima Indians Diabetes Database with bagging 
(random forest), boosting, voting and Stacking methods and display analysis 
accordingly. Compare result. 
import pandas as pd	import numpy as np
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, VotingClassifier, StackingClassifier
from sklearn.linear_model import LogisticRegression	from sklearn.svm import SVC
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import classification_report, accuracy_score

df = pd.read_csv('diabetes.csv')
X = df.drop('Outcome', axis=1)  # Features
y = df['Outcome']  # Target variable
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
rf_model = RandomForestClassifier(n_estimators=100, random_state=42)
rf_model.fit(X_train, y_train)
y_pred_rf = rf_model.predict(X_test)
print("Random Forest Accuracy:", accuracy_score(y_test, y_pred_rf))

ada_model = AdaBoostClassifier(n_estimators=50, random_state=42)
ada_model.fit(X_train, y_train)
y_pred_ada = ada_model.predict(X_test)
print("AdaBoost Accuracy:", accuracy_score(y_test, y_pred_ada))

log_clf = LogisticRegression(max_iter=200)
svc_clf = SVC(probability=True)
voting_clf = VotingClassifier(estimators=[('lr', log_clf), ('svc', svc_clf), ('rf', rf_model)], voting='hard')
voting_clf.fit(X_train, y_train)
y_pred_voting = voting_clf.predict(X_test)
print("Voting Classifier Accuracy:", accuracy_score(y_test, y_pred_voting))

estimators = [('lr', LogisticRegression(max_iter=200)), ('dt', DecisionTreeClassifier())]
stacking_clf = StackingClassifier(estimators=estimators, final_estimator=RandomForestClassifier(random_state=42))
stacking_clf.fit(X_train, y_train)
y_pred_stacking = stacking_clf.predict(X_test)
print("Stacking Classifier Accuracy:", accuracy_score(y_test, y_pred_stacking))

print("\nRandom Forest Classification Report:\n", classification_report(y_test, y_pred_rf))
print("\nAdaBoost Classification Report:\n", classification_report(y_test, y_pred_ada))
print("\nVoting Classifier Classification Report:\n", classification_report(y_test, y_pred_voting))
print("\nStacking Classifier Classification Report:\n", classification_report(y_test, y_pred_stacking))

5.	Write a python program to implement multiple Linear Regression for a house price dataset. Divide the dataset into training and testing data. 

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_absolute_error

data=pd.read_csv("house.csv")
print(data)

x=data[["bedrooms","sqft_living"]]
y=data.price

print(x)
print(y)


xtrain,xtest,ytrain,ytest=train_test_split(x,y,test_size=0.2)
print(xtrain)
print(xtest)
print(ytrain)
print(ytest)

lr=LinearRegression()
lr.fit(xtrain,ytrain)

print(lr.intercept_)
print(lr.coef_)

print(lr.predict([[2,1000]]))


ypred=lr.predict(xtest)
cm=mean_absolute_error(ytest,ypred)
print(cm)

