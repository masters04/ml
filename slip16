19.	Create a two layered neural network with relu and sigmoid activation function. 


import numpy as np
# Set random seed for reproducibility
np.random.seed(42)
# Input data: 3 examples with 2 features each
X = np.array([[0.1, 0.2, 0.3],
              [0.4, 0.5, 0.6]])
# Network architecture
n_input = 2   # Number of input features
n_hidden = 4  # Number of neurons in the hidden layer
n_output = 1  # Output size (binary classification)
# Initialize weights and biases
W1 = np.random.randn(n_hidden, n_input) * 0.01  
b1 = np.zeros((n_hidden, 1))                    
W2 = np.random.randn(n_output, n_hidden) * 0.01 
b2 = np.zeros((n_output, 1))                    
# Forward propagation (without separate functions)
# Layer 1: Hidden Layer
Z1 = np.dot(W1, X) + b1  # Linear transformation
A1 = np.maximum(0, Z1)   # ReLU activation
# Layer 2: Output Layer
Z2 = np.dot(W2, A1) + b2  # Linear transformation
A2 = 1 / (1 + np.exp(-Z2))  # Sigmoid activation
# Output
print("Network Output:\n", A2)


9.	Write a python program to implement Polynomial Linear Regression for Boston Housing Dataset 

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_absolute_error
data=pd.read_csv("housing.csv")
print(data)
x=data[["sqft_living"]]
y=data.price
xtrain,xtest,ytrain,ytest=train_test_split(x,y,test_size=0.2)
lr=LinearRegression()
lr.fit(xtrain,ytrain)
ypred=lr.predict(xtest)
cm=mean_absolute_error(ytest,ypred)
from sklearn.preprocessing import PolynomialFeatures
pr=PolynomialFeatures(degree=2)
xpoly=pr.fit_transform(x)
poreg=LinearRegression()
poreg.fit(xpoly,y)
print(lr.intercept_)
print(lr.coef_)
print(poreg.intercept_)
print(poreg.coef_)
print(lr.predict([[1000]]))
print(poreg.predict(pr.fit_transform([[1000]])))



