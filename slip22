3.	Write a python program to implement simple Linear Regression for predicting house price. First find all null values in a given dataset and remove them. 

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_absolute_error

data=pd.read_csv("house.csv")
print(data)
data=data.dropna(axis=0,how=”any”)
print(data)

x=data[["sqft_living"]]
y=data.price

print(x)
print(y)

plt.scatter(x,y)
plt.xlabel("sqft_living")
plt.ylabel("price")
plt.show()

xtrain,xtest,ytrain,ytest=train_test_split(x,y,test_size=0.2)
print(xtrain)
print(xtest)
print(ytrain)
print(ytest)

lr=LinearRegression()
lr.fit(xtrain,ytrain)

print(lr.intercept_)
print(lr.coef_)

print(lr.predict([[1000]]))


ypred=lr.predict(xtest)
cm=mean_absolute_error(ytest,ypred)
print(cm)


1.	Use Apriori algorithm on groceries dataset to find which items are brought together. Use minimum support =0.25 

import pandas as pd
from mlxtend.preprocessing import TransactionEncoder
from mlxtend.frequent_patterns import apriori, association_rules
groceries = [
    ['milk', 'bread', 'eggs'],
    ['milk', 'bread'],
    ['milk', 'butter', 'bread'],
    ['bread', 'eggs'],
    ['butter', 'eggs']
]

te = TransactionEncoder()
te_ary = te.fit(groceries).transform(groceries)
df = pd.DataFrame(te_ary, columns=te.columns_)

print("Binary Matrix of Transactions:")
print(df)


frequent_itemsets = apriori(df, min_support=0.25, use_colnames=True)

print("\nFrequent Itemsets:")
print(frequent_itemsets)

rules = association_rules(frequent_itemsets, metric="confidence", min_threshold=0.5)

print("\nAssociation Rules:")
print(rules[['antecedents', 'consequents', 'support', 'confidence']])


